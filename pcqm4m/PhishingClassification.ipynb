{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phishing classification\n",
    "\n",
    "### Problem statement\n",
    "As users browse various webpages on the internet, phish webpages attempt to steal users' credentials and often poses a reputational and financial risk.\n",
    "Identifying potential webpages can protect users from these phishing attacks. The objective of this notebook is to analyse the data provided, build a model to predict the probability of webpage being a phish webpage and derive insights to reduce phishing attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import _logger as log\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "\n",
    "from transformers import AdamW, BertConfig, BertTokenizer, BertModel, BertPreTrainedModel, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (75000, 4)\n",
      "Test shape: (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(INPUT_PATH/\"train.csv\"); print(f\"Train shape: {train.shape}\")\n",
    "test = pd.read_csv(INPUT_PATH/\"test.csv\"); print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request_Url</th>\n",
       "      <th>Page_Title</th>\n",
       "      <th>FromPageUrl</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://binanceoption.cash/?a=signup</td>\n",
       "      <td>binanceoption.cash</td>\n",
       "      <td>https://binanceoption.cash/?ref=Tracy45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chrome-native://newtab/</td>\n",
       "      <td>Nowa karta</td>\n",
       "      <td>https://www.bing.com/search?q=nowa+rezydencja+...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://gmail.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://avzz22.com/dolan/index10_15.html</td>\n",
       "      <td>在线亚洲 第15页-www.avzz13.com-豆豆色avzz13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://homoviper.com/?s=3007706&amp;p=0&amp;tb=3ARB44...</td>\n",
       "      <td>https:\\/\\/homoviper.com\\/?s=3007706&amp;p=0&amp;tb=3AR...</td>\n",
       "      <td>https://homoviper.com/?s=6303648&amp;p=0&amp;tb=3ARB44...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Request_Url  \\\n",
       "0               https://binanceoption.cash/?a=signup   \n",
       "1                            chrome-native://newtab/   \n",
       "2                                 https://gmail.com/   \n",
       "3            http://avzz22.com/dolan/index10_15.html   \n",
       "4  https://homoviper.com/?s=3007706&p=0&tb=3ARB44...   \n",
       "\n",
       "                                          Page_Title  \\\n",
       "0                                 binanceoption.cash   \n",
       "1                                         Nowa karta   \n",
       "2                                                NaN   \n",
       "3                 在线亚洲 第15页-www.avzz13.com-豆豆色avzz13   \n",
       "4  https:\\/\\/homoviper.com\\/?s=3007706&p=0&tb=3AR...   \n",
       "\n",
       "                                         FromPageUrl  Label  \n",
       "0            https://binanceoption.cash/?ref=Tracy45      1  \n",
       "1  https://www.bing.com/search?q=nowa+rezydencja+...      0  \n",
       "2                                                NaN      1  \n",
       "3                                                NaN      0  \n",
       "4  https://homoviper.com/?s=6303648&p=0&tb=3ARB44...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request_Url</th>\n",
       "      <th>Page_Title</th>\n",
       "      <th>FromPageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://campusvirtual.cobamich.edu.mx/</td>\n",
       "      <td>Campus Virtual COBAEM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://campusvirtual.cobamich.edu.mx/</td>\n",
       "      <td>campusvirtual.cobamich.edu.mx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://campusvirtual.cobamich.edu.mx/course/vi...</td>\n",
       "      <td>Curso: Metodología de la Investigación#TAB# Mo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://campusvirtual.cobamich.edu.mx/course/vi...</td>\n",
       "      <td>campusvirtual.cobamich.edu.mx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://conditionstray.com/e5wk9k3md8?key=0f22c...</td>\n",
       "      <td>conditionstray.com\\/e5wk9k3md8?key=0f22c1fd609...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Request_Url  \\\n",
       "0              http://campusvirtual.cobamich.edu.mx/   \n",
       "1              http://campusvirtual.cobamich.edu.mx/   \n",
       "2  http://campusvirtual.cobamich.edu.mx/course/vi...   \n",
       "3  http://campusvirtual.cobamich.edu.mx/course/vi...   \n",
       "4  http://conditionstray.com/e5wk9k3md8?key=0f22c...   \n",
       "\n",
       "                                          Page_Title FromPageUrl  \n",
       "0                              Campus Virtual COBAEM         NaN  \n",
       "1                      campusvirtual.cobamich.edu.mx         NaN  \n",
       "2  Curso: Metodología de la Investigación#TAB# Mo...         NaN  \n",
       "3                      campusvirtual.cobamich.edu.mx         NaN  \n",
       "4  conditionstray.com\\/e5wk9k3md8?key=0f22c1fd609...         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "- Request_Url – The Url of the Webpage\n",
    "- Page_Title – The title of the Webpage\n",
    "- FromPageUrl – The Url of the webpage from where Request_Url webpage was loaded/called from.\n",
    "- Label – A binary indicator variable where 1 indicates the Request_Url is a Phishing webpage and 0 indicates a non-Phishing webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = train[\"Label\"].replace({0:\"Non-Phishing\", 1: \"Phishing\"}).value_counts(normalize=True).plot(kind='bar', figsize=(8, 5), rot=0)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable (Phishing/non-Phishing) has an imbalance distribution with approximately 6% of positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Request_Url        0\n",
       "Page_Title      9957\n",
       "FromPageUrl    42411\n",
       "Label              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Request_Url       0\n",
       "Page_Title     2195\n",
       "FromPageUrl    4925\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing complex patterns to identify Phish webpages based on request_url and other metadata is a challenging task, especially considering the amount variation involved in the data. In this notebook, BERT is used in order to build a baseline model for predicting the probablity of phish webpage.\n",
    "\n",
    "### What is BERT?\n",
    "- Bidirectional Encoder Representations from Transformers (BERT) is a Transformer-based machine learning technique for natural language processing.\n",
    "- BERT is pretrained on a large corpus of text data on the web in order to learn the language representation.\n",
    "- Finetuned BERT on custom datasets captures the contextual information to perform wide array of NLP tasks and obtain state-of-the-art results.\n",
    "\n",
    "### Why BERT?\n",
    "- Tokenization process involved in BERT can effectively dissect the request url and page title to derive the hidden patterns of Phish webpages.\n",
    "- BERT allows a seem less way to increase the vocabulary size and learn their representation to improve the model's performance.\n",
    "\n",
    "### Sentence Pair classification\n",
    "In this notebook, sentence pair classification approach is employed to build the classification model using Bert base uncased.\n",
    "Sentence 1: Request_Url  \n",
    "Sentence 2: Page_Title  \n",
    "<center><img src='./assets/images/sentence_pair.png' height=400 width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation scheme: Stratified KFold Cross Validation (K=5)\n",
    "<center><img src='./assets/images/cross_validation.png' height=400 width=500></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(\n",
    "    request_url,\n",
    "    page_title,\n",
    "    from_page_url,\n",
    "    tokenizer,\n",
    "    max_len\n",
    "):\n",
    "    \"\"\"Preprocess text for transformer model consumption\"\"\"\n",
    "    page_title = \" \".join(page_title.strip().split())\n",
    "    text1 = request_url\n",
    "    text2 = page_title\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text1,\n",
    "        text2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding=\"max_length\",\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    ids = inputs[\"input_ids\"]\n",
    "    mask = inputs[\"attention_mask\"]\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "    \n",
    "    return { \n",
    "        \"ids\": ids, \n",
    "        \"mask\": mask, \n",
    "        \"token_type_ids\": token_type_ids\n",
    "    }\n",
    "\n",
    "\n",
    "class PhishingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Torch dataset for Phishing classification\"\"\"\n",
    "    def __init__(self, data, tokenizer, max_len, training=True):\n",
    "        self.request_url = data[\"Request_Url\"].values\n",
    "        self.page_title = data[\"Page_Title\"].values\n",
    "        self.from_page_url = data[\"FromPageUrl\"].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.training = training\n",
    "        if training:\n",
    "            self.label = data[\"Label\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.request_url)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = process_data(\n",
    "                    self.request_url[idx],\n",
    "                    self.page_title[idx],\n",
    "                    self.from_page_url[idx],\n",
    "                    self.tokenizer,\n",
    "                    self.max_len\n",
    "                )\n",
    "        \n",
    "        inputs[\"ids\"] = torch.tensor(inputs[\"ids\"], dtype=torch.long)\n",
    "        inputs[\"mask\"] = torch.tensor(inputs[\"mask\"], dtype=torch.long)\n",
    "        inputs[\"token_type_ids\"] = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long)\n",
    "        \n",
    "        if self.training:\n",
    "            inputs[\"target\"] = torch.tensor(self.label[idx], dtype=torch.float)\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "\n",
    "class PhishingLitDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hparams, train, val, test, tokenizer, max_len):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = PhishingDataset(self.train, self.tokenizer, self.max_len)\n",
    "        self.val_dataset = PhishingDataset(self.val, self.tokenizer, self.max_len)\n",
    "        self.test_dataset = PhishingDataset(\n",
    "            self.test, self.tokenizer, self.max_len, training=False\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.hparams.train_batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataloader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.hparams.test_batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataloader = DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.hparams.test_batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhishingModel(BertPreTrainedModel): \n",
    "    \"\"\"Torch model for Phishing classification\"\"\" \n",
    "    def __init__(self, pretrained_model_path, config): \n",
    "        super(PhishingModel, self).__init__(config) \n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_path, config=config)\n",
    "        self.drop_out = nn.Dropout(0.2) \n",
    "        self.linear = nn.Linear(768, 1) \n",
    "        torch.nn.init.normal_(self.linear.weight, std=0.02)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids): \n",
    "        _, _, out = self.bert( input_ids=ids, attention_mask=mask, token_type_ids=token_type_ids ) \n",
    "        out = out[-1][:, 0]\n",
    "        out = self.drop_out(out) \n",
    "        logits = self.linear(out) \n",
    "        return logits.squeeze()\n",
    "\n",
    "\n",
    "class PhishingLitModel(pl.LightningModule):\n",
    "    def __init__(self, hparams, pretrained_model_path, config):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.model = PhishingModel(\n",
    "            pretrained_model_path=pretrained_model_path,\n",
    "            config=config,\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x[\"ids\"], x[\"mask\"], x[\"token_type_ids\"])\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_logits = self.forward(batch)\n",
    "        loss = self.loss_func(batch_logits, batch[\"target\"])\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch_logits = self.forward(batch)\n",
    "        loss = self.loss_func(batch_logits, batch[\"target\"])\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        num_train_steps = int(\n",
    "            self.hparams.train_size\n",
    "            / self.hparams.train_batch_size\n",
    "            * self.hparams.nb_epochs\n",
    "        )\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": self.hparams.decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_parameters, lr=self.hparams.learning_rate)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.num_warm_steps,\n",
    "            num_training_steps=num_train_steps,\n",
    "        )\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "def predictor(model, data_loader): \n",
    "    model = model.cuda() \n",
    "    model.eval() \n",
    "    predictions = [] \n",
    "    with torch.no_grad(): \n",
    "        tk0 = tqdm(data_loader, total=len(data_loader)) \n",
    "        for _, batch in enumerate(tk0): \n",
    "            ids = batch[\"ids\"].cuda() \n",
    "            mask = batch[\"mask\"].cuda() \n",
    "            token_type_ids = batch[\"token_type_ids\"].cuda() \n",
    "            batch_logits = model(ids, mask, token_type_ids) \n",
    "            probabilities = torch.sigmoid(batch_logits) \n",
    "            predictions.append(probabilities) \n",
    "    predictions = torch.cat(predictions, dim=0).detach().cpu().numpy() \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"For reproducibility\"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NAME = \"phishing\"\n",
    "FOLDS = 5\n",
    "MAX_LEN = 96\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 128\n",
    "NUM_WORKERS = 8\n",
    "SEED = 1729\n",
    "\n",
    "seed_everything(SEED)\n",
    "hparams = {\n",
    "    \"nb_epochs\": 3,\n",
    "    \"train_batch_size\": TRAIN_BATCH_SIZE,\n",
    "    \"test_batch_size\": TEST_BATCH_SIZE,\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"learning_rate\": 0.00002,\n",
    "    \"num_warm_steps\": 200,\n",
    "    \"decay\": 0.0001\n",
    "}\n",
    "hparams = Namespace(**hparams)\n",
    "\n",
    "PRETRAINED_WEIGHTS_PATH = Path(\"pretrained_weights/bert-base-uncased/\")\n",
    "run_path = Path(f\"{SUBMISSION_NAME}\")\n",
    "logs_path = run_path / \"lightning_logs\"\n",
    "model_path = run_path / \"model\"\n",
    "predictions_path = run_path / \"predictions\"\n",
    "predictions_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "INPUT_PATH = Path(\"data\")\n",
    "PRETRAINED_WEIGHTS_PATH = Path(\"pretrained_weights/bert-base-uncased/\")\n",
    "\n",
    "\n",
    "train = pd.read_csv(INPUT_PATH/\"train.csv\")\n",
    "test = pd.read_csv(INPUT_PATH/\"test.csv\")\n",
    "\n",
    "\n",
    "train[\"Page_Title\"] = train[\"Page_Title\"].fillna(\"EMPTY\")\n",
    "train[\"FromPageUrl\"] = train[\"FromPageUrl\"].fillna(\"EMPTY\")\n",
    "\n",
    "\n",
    "test[\"Page_Title\"] = test[\"Page_Title\"].fillna(\"EMPTY\")\n",
    "test[\"FromPageUrl\"] = test[\"FromPageUrl\"].fillna(\"EMPTY\")\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(str(PRETRAINED_WEIGHTS_PATH))\n",
    "config = BertConfig.from_pretrained(str(PRETRAINED_WEIGHTS_PATH))\n",
    "config.output_hidden_states = True\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "for fold, (dev_idx, val_idx) in enumerate(skf.split(train, train[\"Label\"])):\n",
    "    log.info(f\"\\nRunning fold: {fold}\")\n",
    "\n",
    "    fold_start = time.time()\n",
    "    fold_logs_path = logs_path / f\"fold_{fold}\"\n",
    "    fold_model_path = model_path / f\"fold_{fold}\"\n",
    "    if fold_logs_path.exists():\n",
    "        shutil.rmtree(str(fold_logs_path))\n",
    "    if fold_model_path.exists():\n",
    "        shutil.rmtree(str(fold_model_path))\n",
    "\n",
    "    dev = train.loc[dev_idx, :].reset_index(drop=True)\n",
    "    val = train.loc[val_idx, :].reset_index(drop=True)\n",
    "\n",
    "    y_val = train.loc[val_idx, \"Label\"].values\n",
    "    print(dev.shape, val.shape, test.shape)\n",
    "\n",
    "    hparams.train_size = dev.shape[0]\n",
    "\n",
    "    dm = PhishingLitDataModule(hparams, dev, val, test, tokenizer, MAX_LEN)\n",
    "    dm.setup()\n",
    "    model = PhishingLitModel(hparams, PRETRAINED_WEIGHTS_PATH, config)\n",
    "    testtube_logger = TestTubeLogger(\n",
    "        str(fold_logs_path), name=\"PhishingClassification\", version=0\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=f\"{fold_model_path}/phishingclassification_\"\n",
    "        + \"{epoch:02d}-{val_loss_epoch:.4f}\",\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor=\"val_loss_epoch\",\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        weights_summary=\"top\",\n",
    "        num_sanity_val_steps=0,\n",
    "        min_epochs=hparams.nb_epochs,\n",
    "        max_epochs=hparams.nb_epochs,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        logger=testtube_logger,\n",
    "        gpus=1,\n",
    "        deterministic=True,\n",
    "        precision=16,\n",
    "        # fast_dev_run=True\n",
    "    )\n",
    "    trainer.fit(model, dm.train_dataloader(), dm.val_dataloader())\n",
    "\n",
    "    val_probs = predictor(model.model, dm.val_dataloader())\n",
    "    test_probs = predictor(model.model, dm.test_dataloader())\n",
    "\n",
    "    fold_loss_score = metrics.log_loss(y_val, val_probs)\n",
    "    fold_auc_score = metrics.roc_auc_score(y_val, val_probs)\n",
    "\n",
    "    log.info(f\"Val loss: {fold_loss_score:.4f}\")\n",
    "    log.info(f\"Val AUC: {fold_auc_score:.4f}\")\n",
    "\n",
    "    val_fold_probs_df = pd.DataFrame({\"ClassProbability\": val_probs, \"Label\": y_val})\n",
    "    val_fold_probs_df.to_csv(\n",
    "        predictions_path / f\"val_preds_{SUBMISSION_NAME}_fold_{fold}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    test_fold_probs_df = pd.DataFrame({\"ClassProbability\": test_probs})\n",
    "    test_fold_probs_df.to_csv(\n",
    "        predictions_path / f\"test_preds_{SUBMISSION_NAME}_fold_{fold}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    fold_end = time.time()\n",
    "    message = (\n",
    "        f\"Fold: {fold} runtime: {int((fold_end-fold_start) // 60)}m\"\n",
    "        f\" {(fold_end-fold_start) % 60:.0f}s\"\n",
    "    )\n",
    "    log.info(message)\n",
    "\n",
    "    del model, dm, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = train[\"Label\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NAME = \"phishing\"\n",
    "FOLDS = 5\n",
    "run_path = Path(f\"{SUBMISSION_NAME}\")\n",
    "predictions_path = run_path / \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_log_loss_scores = []\n",
    "val_auc_scores = []\n",
    "val_f1_scores = []\n",
    "val_precision_scores = []\n",
    "val_recall_scores = []\n",
    "val_probs_df = pd.DataFrame()\n",
    "final_test_probs = 0\n",
    "for fold in range(FOLDS):\n",
    "    val_fold_probs_df = pd.read_csv(predictions_path / f\"val_preds_{SUBMISSION_NAME}_fold_{fold}.csv\")\n",
    "    val_fold_probs_df[\"Prediction\"] = np.where(val_fold_probs_df[\"ClassProbability\"] > threshold, 1, 0)\n",
    "    val_log_loss_scores.append(metrics.log_loss(val_fold_probs_df[\"Label\"], val_fold_probs_df[\"ClassProbability\"]))\n",
    "    val_auc_scores.append(metrics.roc_auc_score(val_fold_probs_df[\"Label\"], val_fold_probs_df[\"ClassProbability\"]))\n",
    "    val_f1_scores.append(metrics.f1_score(val_fold_probs_df[\"Label\"], val_fold_probs_df[\"Prediction\"]))\n",
    "    val_precision_scores.append(metrics.precision_score(val_fold_probs_df[\"Label\"], val_fold_probs_df[\"Prediction\"]))\n",
    "    val_recall_scores.append(metrics.recall_score(val_fold_probs_df[\"Label\"], val_fold_probs_df[\"Prediction\"]))\n",
    "    \n",
    "    val_probs_df = pd.concat([val_probs_df, val_fold_probs_df], sort=False, ignore_index=True)\n",
    "    \n",
    "    test_fold_probs_df = pd.read_csv(predictions_path / f\"test_preds_{SUBMISSION_NAME}_fold_{fold}.csv\")\n",
    "    final_test_probs += test_fold_probs_df[\"ClassProbability\"]\n",
    "\n",
    "final_test_probs /= FOLDS\n",
    "\n",
    "val_log_loss_scores.append(metrics.log_loss(val_probs_df[\"Label\"], val_probs_df[\"ClassProbability\"]))\n",
    "val_auc_scores.append(metrics.roc_auc_score(val_probs_df[\"Label\"], val_probs_df[\"ClassProbability\"]))\n",
    "val_f1_scores.append(metrics.f1_score(val_probs_df[\"Label\"], val_probs_df[\"Prediction\"]))\n",
    "val_precision_scores.append(metrics.precision_score(val_probs_df[\"Label\"], val_probs_df[\"Prediction\"]))\n",
    "val_recall_scores.append(metrics.recall_score(val_probs_df[\"Label\"], val_probs_df[\"Prediction\"]))\n",
    "\n",
    "val_names = [f\"fold_{i}\" for i in range(FOLDS)] + [\"full\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    \"name\": val_names,\n",
    "    \"log_loss\": val_log_loss_scores,\n",
    "    \"auc\": val_auc_scores,\n",
    "    \"f1\": val_f1_scores,\n",
    "    \"precision\": val_precision_scores,\n",
    "    \"recall\": val_recall_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fold_0</td>\n",
       "      <td>0.052593</td>\n",
       "      <td>0.984924</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.764828</td>\n",
       "      <td>0.884477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fold_1</td>\n",
       "      <td>0.066076</td>\n",
       "      <td>0.978939</td>\n",
       "      <td>0.790567</td>\n",
       "      <td>0.740273</td>\n",
       "      <td>0.848193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fold_2</td>\n",
       "      <td>0.064348</td>\n",
       "      <td>0.977440</td>\n",
       "      <td>0.788216</td>\n",
       "      <td>0.731682</td>\n",
       "      <td>0.854217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fold_3</td>\n",
       "      <td>0.056339</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.784607</td>\n",
       "      <td>0.705091</td>\n",
       "      <td>0.884337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fold_4</td>\n",
       "      <td>0.061744</td>\n",
       "      <td>0.982399</td>\n",
       "      <td>0.796421</td>\n",
       "      <td>0.743215</td>\n",
       "      <td>0.857831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>full</td>\n",
       "      <td>0.060220</td>\n",
       "      <td>0.980623</td>\n",
       "      <td>0.795925</td>\n",
       "      <td>0.736475</td>\n",
       "      <td>0.865815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  log_loss       auc        f1  precision    recall\n",
       "0  fold_0  0.052593  0.984924  0.820312   0.764828  0.884477\n",
       "1  fold_1  0.066076  0.978939  0.790567   0.740273  0.848193\n",
       "2  fold_2  0.064348  0.977440  0.788216   0.731682  0.854217\n",
       "3  fold_3  0.056339  0.981014  0.784607   0.705091  0.884337\n",
       "4  fold_4  0.061744  0.982399  0.796421   0.743215  0.857831\n",
       "5    full  0.060220  0.980623  0.795925   0.736475  0.865815"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- Metrics are consistent across stratified folds.\n",
    "- Higher the False Negatives, higher the risk of Phishing attacks for users. Hence, Recall must be improved by fine tuning the threshold and False Positives must be maintained in the acceptable levels at the same time.\n",
    "\n",
    "### Next steps:\n",
    "- Modify the tokenizer to incorporate information from FromPageUrl to improve the performance.\n",
    "- Devise a better thresholding strategy to obtain acceptable levels of recall.\n",
    "- Build Character-level sequence model to compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_predictions = pd.DataFrame({\"ClassProbability\": final_test_probs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.530927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClassProbability\n",
       "0          0.028654\n",
       "1          0.044322\n",
       "2          0.002699\n",
       "3          0.010454\n",
       "4          0.530927"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_predictions.to_csv(\"phishingclassification_test_probabilities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- https://arxiv.org/pdf/1810.04805.pdf\n",
    "- https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
